我们正在推出一个新的和改进的内容审核工具：Moderation 端点改进了我们以前的内容过滤器，并且今天免费提供给 OpenAI API 开发人员。

![image](https://user-images.githubusercontent.com/13504729/216575834-1afa01fa-d26e-4158-8cfb-3a996ebc6baa.png)

为了帮助开发人员保护他们的应用程序免受可能的滥用，我们引入了更快、更准确的审核端点。该端点为 OpenAI API 开发人员提供了免费访问基于 GPT 的分类器的权限，这些分类器可以检测不需要的内容——这是使用 AI 系统协助人工监督这些系统的一个实例。我们还发布了描述我们的方法和用于评估的数据集的技术论文。

当输入文本时，Moderation 端点会评估内容是色情的、仇恨的、暴力的，还是宣扬自残的内容——我们的内容政策禁止的内容。该端点经过培训，可以快速、准确并在一系列应用程序中稳健运行。重要的是，这减少了产品“说”错话的可能性，即使是在大规模部署给用户时也是如此。因此，人工智能可以在教育等敏感环境中发挥优势，否则无法放心使用它。

![image](https://user-images.githubusercontent.com/13504729/216575945-3de07a94-0ebb-4d2d-8c8f-90a70fbef2f4.png)

Moderation 端点可帮助开发人员从我们的基础设施投资中获益。与其构建和维护自己的分类器——正如我们在论文中记录的那样，这是一个广泛的过程——他们可以通过单个 API 调用访问准确的分类器。

作为 OpenAI致力于使AI 生态系统更安全的承诺的一部分，我们提供此端点以允许免费审核所有 OpenAI API 生成的内容。例如，OpenAI API 客户 Inworld 使用 Moderation 端点来帮助他们基于 AI 的虚拟角色保持适合他们的受众。通过利用 OpenAI 的技术，Inworld 可以专注于他们的核心产品：创造令人难忘的角色。我们目前不支持监测第三方流量。

通过查看文档开始使用审核端点。有关训练过程和模型性能的更多详细信息，请参阅我们的论文。我们还发布了一个评估数据集，其中包含在这些类别中标记的 Common Crawl 数据，我们希望这将促进该领域的进一步研究。
