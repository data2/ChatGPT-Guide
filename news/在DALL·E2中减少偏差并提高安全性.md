今天，我们正在实施一项新技术，以便 DALL·E 生成能够更准确地反映世界人口多样性的人物图像。当 DALL·E 被提示描述一个未指定种族或性别的人（如“消防员”）时，此技术将应用于系统级别。

根据我们的内部评估，在应用该技术后，用户说 DALL·E 图像包含不同背景的人的可能性提高了 12 倍。随着我们收集更多数据和反馈，我们计划随着时间的推移改进这项技术。

![image](https://user-images.githubusercontent.com/13504729/216576324-1569d77d-4580-49bb-b79c-2c2fe59d75ae.png)

4 月，我们开始向有限数量的人预览 DALL·E 2 研究，这使我们能够更好地了解系统的功能和局限性，并改进我们的安全系统。

在此预览阶段，早期用户标记了敏感和有偏见的图像，这些图像有助于告知和评估这种新的缓解措施。

我们正在继续研究 AI 系统（如 DALL·E）如何反映其训练数据中的偏差以及我们解决这些偏差的不同方法。

在研究预览期间，我们采取了其他措施来改进我们的安全系统，包括：

通过拒绝包含真实面孔的图片上传和试图模仿公众人物（包括名人和知名政治人物）的尝试，最大限度地降低 DALL·E 被滥用以创建欺骗性内容的风险。
使我们的内容过滤器更加准确，以便它们更有效地阻止违反我们的内容政策的提示和图像上传，同时仍然允许创意表达。
改进自动化和人工监控系统以防止滥用。
这些改进帮助我们获得了邀请更多用户体验DALL·E的信心。

扩大访问权限是我们负责任地部署 AI 系统的重要组成部分，因为它使我们能够更多地了解现实世界的使用情况，并继续迭代我们的安全系统。
