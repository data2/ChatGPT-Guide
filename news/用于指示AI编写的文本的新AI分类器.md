我们训练了一个分类器来区分人类编写的文本和来自各种提供商的 AI 编写的文本。虽然不可能可靠地检测所有人工智能编写的文本，但我们相信好的分类器可以为人工智能生成的文本是由人类编写的虚假声明提供缓解措施：例如，运行自动错误信息活动，使用人工智能工具进行学术不诚实，以及将 AI 聊天机器人定位为人类。

我们的分类器并不完全可靠。在我们对英语文本“挑战集”的评估中，我们的分类器正确地将 26% 的 AI 编写的文本（真阳性）识别为“可能是 AI 编写的”，同时错误地将 9% 的人类编写的文本标记为 AI 编写的时间（误报）。我们的分类器的可靠性通常会随着输入文本长度的增加而提高。与我们之前发布的分类器相比，这个新的分类器在来自更新的 AI 系统的文本上明显更可靠。

我们正在公开提供此分类器，以获取有关此类不完善的工具是否有用的反馈。我们在检测 AI 生成的文本方面的工作将继续，我们希望在未来分享改进的方法。

我们的分类器有许多重要的局限性。它不应该被用作主要的决策工具，而是作为其他确定一段文本来源的方法的补充。

分类器在短文本（少于 1,000 个字符）上非常不可靠。甚至更长的文本有时会被分类器错误地标记。
有时，人类编写的文本会被我们的分类器错误但自信地标记为 AI 编写的。
我们建议仅对英文文本使用分类器。它在其他语言中的表现要差得多，并且在代码上不可靠。
无法可靠地识别非常可预测的文本。例如，无法预测前 1000 个素数的列表是由人工智能还是人类编写的，因为正确答案总是相同的。
可以编辑 AI 编写的文本以避开分类器。像我们这样的分类器可以根据成功的攻击进行更新和再训练，但目前尚不清楚检测是否具有长期优势。
众所周知，基于神经网络的分类器在其训练数据之外的校准很差。对于与我们训练集中的文本有很大不同的输入，分类器有时非常有信心做出错误的预测。
训练分类器
我们的分类器是一种语言模型，针对同一主题的人工文本和 AI 文本对的数据集进行了微调。我们从我们认为是由人类编写的各种来源收集了这个数据集，例如预训练数据和提交给InstructGPT的提示的人类演示。我们将每个文本分为提示和响应。根据这些提示，我们生成了来自我们和其他组织训练的各种不同语言模型的响应。对于我们的网络应用程序，我们调整置信度阈值以保持较低的误报率；换句话说，如果分类器非常有信心，我们只会将文本标记为可能是 AI 编写的。

对教育工作者的影响和征求意见
我们认识到识别 AI 编写的文本一直是教育工作者讨论的一个重要问题，同样重要的是认识到 AI 生成的文本分类器在课堂上的局限性和影响。我们已经为教育工作者开发了关于使用 ChatGPT的初步资源，其中概述了一些用途以及相关的限制和注意事项。虽然此资源主要针对教育工作者，但我们希望我们的分类器和相关分类器工具能够对记者、错误/虚假信息研究人员和其他群体产生影响。

我们正在与美国的教育工作者合作，了解他们在课堂上看到的内容，并讨论 ChatGPT 的功能和局限性，我们将在学习的过程中继续扩大我们的影响范围。这些都是重要的对话，因为我们使命的一部分是安全地部署大型语言模型，与受影响的社区直接联系。

如果您直接受到这些问题的影响（包括但不限于教师、管理人员、家长、学生和教育服务提供商），请使用此表格向我们提供反馈。对初步资源的直接反馈很有帮助，我们也欢迎教育工作者正在开发或发现有帮助的任何资源（例如，课程指南、荣誉准则和政策更新、交互式工具、AI 扫盲计划）。

